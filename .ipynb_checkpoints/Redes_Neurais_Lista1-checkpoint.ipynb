{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado supervisionado:\n",
    "\n",
    "O aprendizado supervisionado pode ser comparado com um cenário em que há a presença de um professor, em que este detém conhecimento do ambiente desconhecido sobre o qual a máquina está tentando aprender. Esse conhecimento prévio é geralmente um conjunto de dados na forma entrada-saída.\n",
    "\n",
    "Assim, o professor fornece à Rede Neural qual a saída desejada para uma determinada entrada e os parâmetros da rede são ajustados levando em consideração a informação fornecida pelo professor e um sinal de erro (Saída desejada - Resposta do sistema). O objetivo é que, com os ajustes dos parâmetros, seja possível tratar corretamente novas entradas (não-rotuladas). \n",
    "\n",
    "Aprendizado por regressão e classificação são dois exemplos de aprendizado supervisionado. Em regressão, a saída é numérica. Por exemplo, em uma rede de telefonia celular, pode-se desejar prever qual a vazão de um usuário de acordo com sua localização em relação à estação rádio-base, seu histórico de vazão, etc. Em problemas de classificação, a saída da rede é um código indicando uma classe. Por exemplo, um cenário em que um banco deseja classificar os cliente em grupos de acordo com sua probabilidade de pagar um empréstimo (baixo risco, alto risco, médio risco) de acordo com alguns dados como: idade, salário, etc.\n",
    "\n",
    "### Aprendizado não-supervisionado:\n",
    "\n",
    "Em aprendizado não-supervisionado não há a figura do professor. A rede neural dispõe apenas dos dados de entrada e o objetivo é encontrar padrões. Por exemplo, pode-se operar através do clustering, ou seja, formar grupos de dados por similaridade. Ou seja, o sistema tem o objetivo de representar os dados para tomada de decisões, previsões de entradas futuras, etc.\n",
    "\n",
    "Um bom exemplo de aprendizado não-supervisionado está em algoritmos de compressão de imagens, em que pixels que representam tons de uma mesma cor podem ser agrupados (clustering).\n",
    "\n",
    "### Semi-supervisionado:\n",
    "\n",
    "O aprendizado semi-supervisionado permite à rede aprender através de exemplos rotulados e não rotulados. Esse tipo de aprendizado surgiu pois exemplos rotulados são mais raros em comparação a exemplos não rotulados. Assim, os exemplos rotulados são utilizados para o aprendizado inicial, de forma que seja possível continuar o processo com os dados não rotulados. \n",
    "\n",
    "É possível utilizar o aprendizado semi-supervisionado em problemas de classificação ou clustering. Por exemplo, em problemas de clustering, os exemplos rotulados são usados no processo de formação dos clusters. Possuir informação prévia sobre os dados que irão formar os cluster geralmente rende melhores resultados.\n",
    "\n",
    "Um exemplo é o algoritmo Co-training, introduzido em 1998, que precisa apenas de um pequeno conjunto de exemplos rotulados. Seu conceito principal é a utilização de dois classificadores que rotulam exemplos um para o outro, aumentando a precisão do processo de classificação. O artigo original que propôs o Co-training utilizou um experimento consistindo na classificação de páginas web como \"página inicial de um curso acadêmico\" ou não. O algoritmo classificou corretamente 788 páginas com apenas 12 exemplos rotulados inicialmente (95% de sucesso).\n",
    "\n",
    "### Aprendizado por reforço:\n",
    "\n",
    "No aprendizado por reforço, assim como no aprendizado não-supervisionado, não há a figura do professor, ou seja, a Rede Neural não possui informação do ambiente. O aprendizado acontece através de uma contínua interação com o ambiente, com o objetivo de minimizar algum indicador de performance.  \n",
    "\n",
    "Em problemas de aprendizagem por reforço, a resposta do sistema é uma sequência de ações. De forma que seu objetivo é minimizar uma função de custo que na verdade representa o acúmulo do custo de diversas ações, tomadas em sequência. Ou seja, o algoritmo deve encontrar as ações que são melhores para o sistema em geral, pois nesse caso uma só ação não é mais importante, mas o conjunto certo de ações que leva ao resultado esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da matriz de covariância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse é o vetor X, formado pelos vetores aleatórios: \n",
      "\n",
      " [[5 2 4]\n",
      " [4 6 7]\n",
      " [3 2 4]\n",
      " [3 6 5]] \n",
      "\n",
      "Esse é o vetor média: \n",
      "\n",
      " [[ 5.        ]\n",
      " [ 5.33333333]\n",
      " [ 6.66666667]] \n",
      "\n",
      "Matriz de Covariância S:\n",
      "\n",
      " [[ 0.91666667 -0.66666667  0.        ]\n",
      " [-0.66666667  5.33333333  2.66666667]\n",
      " [ 0.          2.66666667  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "#definindo os vetores das variáveis aleatórias\n",
    "x1 = np.matrix('5;2;4')\n",
    "x2 = np.matrix('4;6;7')\n",
    "x3 = np.matrix('3;2;4')\n",
    "x4 = np.matrix('3;6;5')\n",
    "\n",
    "#definindo os vetores aleatórios como uma matriz\n",
    "x = np.matrix('5 2 4; 4 6 7; 3 2 4; 3 6 5')\n",
    "print('Esse é o vetor X, formado pelos vetores aleatórios: \\n\\n',x,'\\n')\n",
    "\n",
    "#calculando o vetor média\n",
    "x_media = np.matrix([ [ np.sum(x[:,0])/3 ], [ (np.sum(x[:,1]))/3] , [(np.sum(x[:,2]))/3] ])\n",
    "print('Esse é o vetor média: \\n\\n',x_media,'\\n')\n",
    "\n",
    "#definindo a matriz covariância\n",
    "x = x.transpose()\n",
    "s = np.cov(x)\n",
    "print('Matriz de Covariância S:\\n\\n',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da forma fatorada da Matriz de Covariância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autovalores da matriz S:\n",
      "\n",
      "  [ 6.86860959  1.05395536  0.32743504] \n",
      "\n",
      "Autovetores da Matriz S: \n",
      "\n",
      " [[-0.09776694 -0.85145428 -0.51523513]\n",
      " [ 0.87285487  0.17534257 -0.45538924]\n",
      " [ 0.47808577 -0.4942475   0.72605331]]\n",
      "\n",
      " Matriz diagonal dos autovalores (D):\n",
      "\n",
      " [[ 6.86860959  0.          0.        ]\n",
      " [ 0.          1.05395536  0.        ]\n",
      " [ 0.          0.          0.32743504]]\n",
      "\n",
      " Matriz S calculada pela forma fatorada: V*D*V^-1 \n",
      "\n",
      " [[  9.16666667e-01  -6.66666667e-01   5.13653021e-16]\n",
      " [ -6.66666667e-01   5.33333333e+00   2.66666667e+00]\n",
      " [  4.65733420e-16   2.66666667e+00   2.00000000e+00]]\n",
      "\n",
      " É possível perceber que coincide com a matriz S calculada anteriormente.\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "#cálculo dos autovalores e autovetores\n",
    "d,v = LA.eig(s)\n",
    "print('Autovalores da matriz S:\\n\\n ',d,'\\n\\nAutovetores da Matriz S: \\n\\n',v)\n",
    "\n",
    "#formando a matriz D\n",
    "d2 = np.matrix([ [d[0],0,0],[0,d[1],0],[0,0,d[2]]  ])\n",
    "print('\\n Matriz diagonal dos autovalores (D):\\n\\n',d2)\n",
    "\n",
    "#print(d,'\\n\\n',v)\n",
    "\n",
    "v_1 = inv(v)\n",
    "\n",
    "print('\\n Matriz S calculada pela forma fatorada: V*D*V^-1 \\n\\n',v*d2*v_1)\n",
    "print('\\n É possível perceber que coincide com a matriz S calculada anteriormente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de $S^3$ através da forma fatorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[   3.95543981,  -27.81944444,  -14.66666667],\n",
       "        [ -27.81944444,  246.92592593,  135.11111111],\n",
       "        [ -14.66666667,  135.11111111,   74.37037037]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de s³\n",
    "v*d2*d2*d2*v_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3.95543981,  -27.81944444,  -14.66666667],\n",
       "       [ -27.81944444,  246.92592593,  135.11111111],\n",
       "       [ -14.66666667,  135.11111111,   74.37037037]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de s³ de forma direta, para efeito de comparação\n",
    "s2 = np.matmul(s,s)\n",
    "np.matmul(s,s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da Norma Euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a norma Euclidiana da matriz: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8686095911265861"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(s, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando o traço da matriz S para comparação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0,0]+s[1,1]+s[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma euclidiana dos vetores aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7082039325\n",
      "10.0498756211\n",
      "5.38516480713\n",
      "8.36660026534\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(x1, ord=2))\n",
    "print(np.linalg.norm(x2, ord=2))\n",
    "print(np.linalg.norm(x3, ord=2))\n",
    "print(np.linalg.norm(x4, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma de Mahalanobis dos vetores aleatórios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/60cac59afa88452a425a87659f960ce63118c93c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.94506098]]\n",
      "[[ 6.48796964]]\n",
      "[[ 4.34093884]]\n",
      "[[ 4.90853848]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt((x1).transpose()*inv(s)*(x1)))\n",
    "print(np.sqrt((x2).transpose()*inv(s)*(x2)))\n",
    "print(np.sqrt((x3).transpose()*inv(s)*(x3)))\n",
    "print(np.sqrt((x4).transpose()*inv(s)*(x4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se a matriz de covariância for a identidade, coincide com a Norma euclidiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.70820393]]\n",
      "[[ 10.04987562]]\n",
      "[[ 5.38516481]]\n",
      "[[ 8.36660027]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt((x1).transpose()*(x1)))\n",
    "print(np.sqrt((x2).transpose()*(x2)))\n",
    "print(np.sqrt((x3).transpose()*(x3)))\n",
    "print(np.sqrt((x4).transpose()*(x4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição de probabilidade dos vetores aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADm1JREFUeJzt3X+s3XV9x/HnS8r8gWxgetfUttklpjPBJSvkhrFhjBtT\n+WEs/kNKMiTEpP6BC2wmS/Ef3R8kLFFcTDaSKoyaIazjR2ykcTJG4vgD9LYyflViJ0XaFXqdm+Bc\ndMB7f9wv80zbe8+Pe/hyPzwfyck953O+3/t9Q3Kf/fZ7zzlNVSFJatcb+h5AkjRdhl6SGmfoJalx\nhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxa/oeAGDt2rU1Ozvb9xiStKrs27fvB1U1s9x2r4nQ\nz87OMj8/3/cYkrSqJHl6mO28dCNJjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9J\njXtNvDNWei2b3XFPL8c9dP3FvRxX7fGMXpIaZ+glqXGGXpIaZ+glqXGGXpIat2zok2xKcn+SJ5I8\nnuTqbv3TSY4kebi7XTSwz7VJDiZ5MskHpvkfIEla2jAvr3wR+ERV7U9yKrAvyb3dc5+rqs8Mbpzk\nTGAb8C7g7cA/JvnNqnppJQeXJA1n2TP6qjpaVfu7+y8AB4ANS+yyFbi9qn5aVU8BB4FzVmJYSdLo\nRrpGn2QWOAt4qFv6eJJHktyc5PRubQPwzMBuhznOHwxJtieZTzK/sLAw8uCSpOEMHfokbwXuBK6p\nqueBG4F3AFuAo8BnRzlwVe2sqrmqmpuZWfbftpUkjWmo0Cc5mcXI31pVdwFU1XNV9VJVvQx8gZ9f\nnjkCbBrYfWO3JknqwTCvuglwE3Cgqm4YWF8/sNmHgce6+3uAbUnemOQMYDPwzZUbWZI0imFedXMe\ncDnwaJKHu7VPApcl2QIUcAj4GEBVPZ5kN/AEi6/YucpX3EhSf5YNfVU9AOQ4T+1dYp/rgOsmmEuS\ntEJ8Z6wkNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjhnlnrKQezO64p5fjHrr+4l6O\nq+nxjF6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalx\nhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGrds6JNsSnJ/kieSPJ7k6m79\nbUnuTfLd7uvp3XqSfD7JwSSPJDl72v8RkqQTG+aM/kXgE1V1JnAucFWSM4EdwH1VtRm4r3sMcCGw\nubttB25c8aklSUNbNvRVdbSq9nf3XwAOABuArcCubrNdwCXd/a3Al2rRg8BpSdav+OSSpKGMdI0+\nySxwFvAQsK6qjnZPPQus6+5vAJ4Z2O1wtyZJ6sHQoU/yVuBO4Jqqen7wuaoqoEY5cJLtSeaTzC8s\nLIyyqyRpBEOFPsnJLEb+1qq6q1t+7pVLMt3XY936EWDTwO4bu7X/p6p2VtVcVc3NzMyMO78kaRnD\nvOomwE3Agaq6YeCpPcAV3f0rgK8MrH+ke/XNucCPBi7xSJJeZWuG2OY84HLg0SQPd2ufBK4Hdif5\nKPA0cGn33F7gIuAg8BPgyhWdWJI0kmVDX1UPADnB0+cfZ/sCrppwLknSCvGdsZLUOEMvSY0z9JLU\nOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUuGE+1Ezq3eyOe/oeQVq1PKOXpMYZ\neklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklq\nnKGXpMYZeklqnKGXpMYZeklqnKGXpMYtG/okNyc5luSxgbVPJzmS5OHudtHAc9cmOZjkySQfmNbg\nkqThDHNGfwtwwXHWP1dVW7rbXoAkZwLbgHd1+/x1kpNWalhJ0uiWDX1VfQP44ZDfbytwe1X9tKqe\nAg4C50wwnyRpQpNco/94kke6Szund2sbgGcGtjncrf2SJNuTzCeZX1hYmGAMSdJSxg39jcA7gC3A\nUeCzo36DqtpZVXNVNTczMzPmGJKk5YwV+qp6rqpeqqqXgS/w88szR4BNA5tu7NYkST0ZK/RJ1g88\n/DDwyity9gDbkrwxyRnAZuCbk40oSZrEmuU2SHIb8F5gbZLDwKeA9ybZAhRwCPgYQFU9nmQ38ATw\nInBVVb00ndElScNYNvRVddlxlm9aYvvrgOsmGUqStHJ8Z6wkNc7QS1LjDL0kNc7QS1Ljlv1lrKTX\nl9kd9/R27EPXX9zbsVvmGb0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7Q\nS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1Lj\nDL0kNc7QS1LjDL0kNW7Z0Ce5OcmxJI8NrL0tyb1Jvtt9Pb1bT5LPJzmY5JEkZ09zeEnS8oY5o78F\nuOAX1nYA91XVZuC+7jHAhcDm7rYduHFlxpQkjWvZ0FfVN4Af/sLyVmBXd38XcMnA+pdq0YPAaUnW\nr9SwkqTRjXuNfl1VHe3uPwus6+5vAJ4Z2O5wtyZJ6snEv4ytqgJq1P2SbE8yn2R+YWFh0jEkSScw\nbuife+WSTPf1WLd+BNg0sN3Gbu2XVNXOqpqrqrmZmZkxx5AkLWfc0O8BrujuXwF8ZWD9I92rb84F\nfjRwiUeS1IM1y22Q5DbgvcDaJIeBTwHXA7uTfBR4Gri023wvcBFwEPgJcOUUZpYkjWDZ0FfVZSd4\n6vzjbFvAVZMOJUlaOb4zVpIaZ+glqXHLXrqRBs3uuKfvESSNyDN6SWqcoZekxhl6SWqcoZekxhl6\nSWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqc\noZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxq2ZZOckh4AX\ngJeAF6tqLsnbgL8DZoFDwKVV9R+TjSlJGtdKnNH/flVtqaq57vEO4L6q2gzc1z2WJPVkGpdutgK7\nuvu7gEumcAxJ0pAmDX0BX0+yL8n2bm1dVR3t7j8LrDvejkm2J5lPMr+wsDDhGJKkE5noGj3w7qo6\nkuTXgXuTfGfwyaqqJHW8HatqJ7ATYG5u7rjbSJImN9EZfVUd6b4eA+4GzgGeS7IeoPt6bNIhJUnj\nGzv0SU5Jcuor94H3A48Be4Arus2uAL4y6ZCSpPFNculmHXB3kle+z5er6mtJvgXsTvJR4Gng0snH\nlCSNa+zQV9X3gN8+zvq/A+dPMpQkaeVM+stYSVoxszvu6eW4h66/uJfjvlr8CARJapyhl6TGGXpJ\napyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyf\nR78K9fWZ3VKr+vyZejU+C98zeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklq\nnKGXpMYZeklqnKGXpMb5oWYT8MPFJK0GUzujT3JBkieTHEyyY1rHkSQtbSpn9ElOAv4KeB9wGPhW\nkj1V9cRKH8uzakla2rTO6M8BDlbV96rqZ8DtwNYpHUuStIRphX4D8MzA48PdmiTpVdbbL2OTbAe2\ndw9/nOTJvmaZwFrgB30PMQHn75fz9+s1MX/+Yuxd1wK/McyG0wr9EWDTwOON3dr/qaqdwM4pHf9V\nkWS+qub6nmNczt8v5+9XI/PPDrPttC7dfAvYnOSMJL8CbAP2TOlYkqQlTOWMvqpeTPJx4B+Ak4Cb\nq+rxaRxLkrS0qV2jr6q9wN5pff/XiFV96Qnn75vz9+t1M3+qapqDSJJ65mfdSFLjDP0YkmxKcn+S\nJ5I8nuTqvmcaRZI3Jflmkn/p5v/zvmcaVZKTknw7yVf7nmUcSQ4leTTJw0nm+55nVElOS3JHku8k\nOZDkd/ueaVhJ3tn9f3/l9nySa/qeaxRJ/qT72X0syW1J3rTk9l66GV2S9cD6qtqf5FRgH3DJND7i\nYRqSBDilqn6c5GTgAeDqqnqw59GGluRPgTngV6vqg33PM6okh4C5qur9ddzjSLIL+Oeq+mL3yrq3\nVNV/9j3XqLqPazkC/E5VPd33PMNIsoHFn9kzq+q/k+wG9lbVLSfaxzP6MVTV0ara391/ATjAKnrn\nby36cffw5O62av7ET7IRuBj4Yt+zvB4l+TXgPcBNAFX1s9UY+c75wL+ulsgPWAO8Ocka4C3Avy21\nsaGfUJJZ4CzgoX4nGU136eNh4Bhwb1Wtpvn/Evgz4OW+B5lAAV9Psq97l/hqcgawAPxNd/nsi0lO\n6XuoMW0Dbut7iFFU1RHgM8D3gaPAj6rq60vtY+gnkOStwJ3ANVX1fN/zjKKqXqqqLSy+a/mcJL/V\n90zDSPJB4FhV7et7lgm9u6rOBi4Erkrynr4HGsEa4Gzgxqo6C/gvYNV9FHl3yelDwN/3PcsokpzO\n4odEngG8HTglyR8ttY+hH1N3bftO4NaquqvvecbV/ZX7fuCCvmcZ0nnAh7pr3LcDf5Dkb/sdaXTd\nWRlVdQy4m8VPfF0tDgOHB/4WeAeL4V9tLgT2V9VzfQ8yoj8Enqqqhar6H+Au4PeW2sHQj6H7ZeZN\nwIGquqHveUaVZCbJad39N7P47wZ8p9+phlNV11bVxu4zPrYB/1RVS57NvNYkOaX7JT7dJY/3A4/1\nO9XwqupZ4Jkk7+yWzgdWxQsRfsFlrLLLNp3vA+cmeUvXovNZ/D3hCflPCY7nPOBy4NHuOjfAJ7t3\nA68G64Fd3SsO3gDsrqpV+TLFVWodcPfizyhrgC9X1df6HWlkfwzc2l3++B5wZc/zjKT7A/Z9wMf6\nnmVUVfVQkjuA/cCLwLdZ5l2yvrxSkhrnpRtJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyh\nl6TG/S9jSpVsCI62GQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb4b40cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g1 = np.random.normal(x_media[0,0], np.sqrt(s[0,0]), 1000)\n",
    "plt.hist(g1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb7ba81748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g2 = np.random.normal(x_media[1,0], np.sqrt(s[1,1]), 1000)\n",
    "plt.hist(g2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb4b518f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "g3 = np.random.normal(x_media[2,0], np.sqrt(s[2,2]), 1000)\n",
    "plt.hist(g3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método do gradiente conjugado\n",
    "\n",
    "Para esse método consideramos a minimização da função quadrática:\n",
    "\n",
    "$$ f(x)= (1/2) x^TAx -b^Tx + c $$\n",
    "\n",
    "Como a forma é quadrática, há apenas um vector que minimiza $f$, que é o ponto crítico, solução de:\n",
    "\n",
    "$$ \\nabla f(x) = 0 $$\n",
    "\n",
    "E, nesse caso: \n",
    "\n",
    "$$ f(x) = \\nabla (1/2)(A^T+A)x-b = Ax -b $$\n",
    "\n",
    "Assim, se encontrarmos o ponto de mínimo, ele será solução do sistema linear $Ax = b$\n",
    "\n",
    "Consideramos métodos iterativos de optimização do tipo:\n",
    "\n",
    "$$ x^{(n+1)} = x^{(n)}+ a_n r^{(n)} $$\n",
    "\n",
    "de forma a que haja uma descida, ou seja, $f(x^{(n+1)}) < f(x^{(n)})$. O vector $r^{(n)}$ define a direcção de descida.\n",
    "\n",
    "Dois vetores $\\textbf{x}$ e $\\textbf{y}$ são ditos com direção conjugadas se:\n",
    "\n",
    "$$ <u,v>_A= u . Av = u^TAv $$\n",
    "\n",
    "$$ <u,v>_A= u . Av = 0 $$\n",
    "\n",
    "Seja N a dimensão da matriz A e sejam d(0), ..., d(N-1) direcções conjugadas\n",
    "\n",
    "Se considerarmos d^{(n)} como direcções de descida, temos a iteração\n",
    "\n",
    "$$ x^{(n+1)} = x^{(n)} + a_nd^{(n)} $$\n",
    "\n",
    "Queremos agora encontrar o valor $a_n$ que minimiza $f$, de entre os possíveis valores  $x^{(n)} + ad^{(n)}$\n",
    "\n",
    "De forma, semelhante, podemos obter\n",
    "\n",
    "$$ \\frac{d}{da}  f(x^{(n)} + ad^{(n)}) =  r^{(n)} \\cdot d^{(n)}-aAd^{(n)}\\cdot d^{(n)} $$\n",
    "\n",
    "e assim \n",
    "\n",
    "$$ a_n = r^{(n)} \\cdot \\frac{d^{(n)}}{d^{(n)} . Ad^{(n)}} $$\n",
    "\n",
    "Sendo que: \n",
    "\n",
    "$$  r^{(n)} =  b - Ax^{(n)} $$ \n",
    "\n",
    "Obtemos de forma genérica, um método de direcções conjugadas:\n",
    "\n",
    "$$x^{(n+1)} = x^{(n)} + \\frac{ r^{(n)} \\cdot d^{(n)} }{ d^{(n)} \\cdot ad^{(n)} } d^{(n)}$$\n",
    "\n",
    "mas ainda não definimos as direcções $d^{(n)}$, apenas assumimos que existiam a priori, e eram conjugadas.\n",
    "\n",
    "Assim, o caso particular do método das direcções conjugadas é o método do gradiente conjugado, em que elas são obtidas através do gradiente. \n",
    "\n",
    "Recordamos que no caso linear o gradiente é dado pelo resíduo $r^{(n)} =  b - Ax^{(n)}.$ \n",
    "Através de um processo de ortogonalização de Gram-Schmidt, através dos sucessivos resíduos (gradientes) podemos construir as direcções $d^{(n)}$ que serão conjugadas. \n",
    "\n",
    "Assim, podemos resumir o Método dos Gradientes Conjugados:\n",
    "\n",
    "1. Dado $ x^{(0)}$ definimos $ d^{(0)} = r^{(0)} = b-Ax^{(0)}$\n",
    "\n",
    "2. Definimos $x^{(n+1)} = x^{(n)}+ a_n d^{(n)}$, com $a_n = r^{(n)} \\cdot \\frac {d^{(n)}}  {d^{(n)} \\cdot Ad^{(n)}}$\n",
    "\n",
    "3. Definimos $r^{(n+1)} = r^{(n)} - a_n Ad^{(n)},$ e $d^{(n+1)} = r^{(n+1)} + b_n d^{(n)},$ com $b_n =  r^{(n+1)} \\cdot \\frac {r^{(n+1)}}{r^{(n)} \\cdot r^{(n)}}$\n",
    "\n",
    "4. Regressamos ao 2º passo, até alcançar critério de parada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função a ser minimizada:\n",
    "\n",
    "$$ f(x) = 8x_1^2 - x_1x_2 + 10x^2 + x_1 + x_2 - 5$$\n",
    "\n",
    "Está sujeito à restrição abaixo:\n",
    "\n",
    "$$ g_1(x_1,x_2) = x_1 + x_2 = 0$$ \n",
    "\n",
    "Logo:\n",
    "\n",
    "$$L(x_1,x_2,\\lambda) = L (x_1,x_2) - \\lambda R(x_1,x_2) $$\n",
    "\n",
    "$$L(x_1,x_2,\\lambda) = 8x_1^2 - x_1x_2 + 10x^2 + x_1 + x_2 - 5 - \\lambda x_1 - \\lambda x_2 $$\n",
    "\n",
    "Em seguida:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial x_1} = 16x_1 - x_2 + 1 - \\lambda$$\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial x_2} = -x_1 + 20x_2 + 1 - \\lambda$$\n",
    "\n",
    "Assim, podemos resolver o sistma com três equações:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial x_1} = 16x_1 - x_2 + 1 - \\lambda$$\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial x_2} = -x_1 + 20x_2 + 1 - \\lambda$$\n",
    "\n",
    "$$ x_1 + x_2 = 0$$ \n",
    "\n",
    "Resolvendo o sistema:\n",
    "\n",
    "$$ 16x_1 - x_2 + 1 = -x_1 + 20x_2 + 1 $$\n",
    "\n",
    "$$ 17x_1 - 21x_2 = 0 $$\n",
    "\n",
    "$$ -17x_1 - 21x_2 = 0 $$\n",
    "\n",
    "Logo, de acordo com as expressões acima:\n",
    "\n",
    "$$ x_1 = x_2 = 0 $$\n",
    "\n",
    "$$\\lambda = 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
